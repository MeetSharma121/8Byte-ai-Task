# ğŸš€ Advanced Dockerized Stock Market Data Pipeline ğŸ“Š

This enterprise-grade project implements a comprehensive data engineering solution for fetching, processing, storing, and visualizing stock market data. Built with scalability, resilience, and observability in mind, this system leverages modern technologies to provide a complete end-to-end solution. âœ¨

## âœ… Key Features

- ğŸ”„ **Orchestrated Data Pipeline**: Automated workflow using Apache Airflow with scheduled execution
- âš¡ **Real-time Data Access**: RESTful API with Redis caching for high-performance data retrieval
- ğŸ“ˆ **Advanced Visualization**: Interactive Grafana dashboards for data analysis and monitoring
- ğŸ‘ï¸ **Complete Observability**: Prometheus metrics collection for system monitoring
- ğŸ”§ **High Scalability**: Distributed architecture with separate services for different concerns
- ğŸ”’ **Enterprise Security**: Environment-based configuration and secure credential management
- ğŸ›¡ï¸ **Fault Tolerance**: Comprehensive error handling and recovery mechanisms

## ğŸ—ï¸ Architecture

The system is built using a microservices architecture with the following components:

- ğŸŒªï¸ **Airflow**: Orchestrates the data pipeline and schedules data fetching
- ğŸ˜ **PostgreSQL**: Stores the stock market data in a structured format
- ğŸ”´ **Redis**: Provides caching for API responses to improve performance
- ğŸŒ **Flask API**: Exposes RESTful endpoints for data access with Swagger documentation
- ğŸ“Š **Grafana**: Provides interactive dashboards for data visualization
- ğŸ“¡ **Prometheus**: Collects and stores metrics for monitoring system performance

## ğŸ“‹ Prerequisites

- ğŸ³ Docker and Docker Compose installed on your system
- ğŸŒ Internet connection to access the Yahoo Finance API

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Dockerfile.api
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements.api.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ stock_data_pipeline.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ fetch_stock_data.py
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ database.py
â”‚   â””â”€â”€ models.py
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â””â”€â”€ stock_dashboard.json
â”‚   â””â”€â”€ provisioning/
â”‚       â”œâ”€â”€ dashboards/
â”‚       â”‚   â””â”€â”€ dashboards.yml
â”‚       â””â”€â”€ datasources/
â”‚           â””â”€â”€ datasource.yml
â””â”€â”€ prometheus/
    â””â”€â”€ prometheus.yml
```

## ğŸš€ Setup Instructions

1. ğŸ“¥ Clone this repository
2. ğŸ“ Copy `.env.example` to `.env` and fill in your configuration values
3. ğŸ—ï¸ Build and start the containers:

```bash
docker-compose up -d
```

4. ğŸŒ Access the following interfaces:
   - ğŸŒªï¸ **Airflow**: http://localhost:8080 (Username: airflow, Password: airflow)
   - ğŸ“š **API Documentation**: http://localhost:5000/docs
   - ğŸ“Š **Grafana Dashboards**: http://localhost:3000 (Username: admin, Password: admin)
   - ğŸ“¡ **Prometheus Metrics**: http://localhost:9090

5. â±ï¸ The data pipeline will run automatically according to the schedule (daily by default)

## ğŸ”Œ API Endpoints

The system provides a RESTful API for accessing stock data:

- ğŸ“‹ `GET /stocks/`: List all stock data with pagination
- ğŸ·ï¸ `GET /stocks/symbols`: List all available stock symbols
- ğŸ“ˆ `GET /stocks/{symbol}`: Get the latest stock data for a specific symbol
- ğŸ“… `GET /stocks/{symbol}/history`: Get historical stock data for a specific symbol

## ğŸ“Š Monitoring and Visualization

The system includes comprehensive monitoring and visualization capabilities:

- ğŸ“Š **Grafana Dashboards**: Pre-configured dashboards for stock price trends, volume analysis, and system metrics
- ğŸ“¡ **Prometheus Metrics**: Real-time monitoring of API performance, data pipeline execution, and system health

## âš™ï¸ Configuration

You can configure the following parameters in the `.env` file:

- ğŸ‘¤ `POSTGRES_USER`: PostgreSQL username
- ğŸ”‘ `POSTGRES_PASSWORD`: PostgreSQL password
- ğŸ’¾ `POSTGRES_DB`: PostgreSQL database name
- ğŸ¢ `STOCK_SYMBOLS`: Comma-separated list of stock symbols to track (e.g., AAPL,MSFT,GOOGL)
- ğŸ‘¤ `GRAFANA_USER`: Grafana admin username
- ğŸ”‘ `GRAFANA_PASSWORD`: Grafana admin password

## ğŸ”§ Extending the System

### ğŸ“Š Adding New Data Sources

To add new data sources, create a new Python module in the `scripts` directory and update the Airflow DAG to include the new data fetching task.

### ğŸ¨ Creating Custom Visualizations

You can create Grafana dashboards by importing JSON definitions or using the Grafana UI to build new visualizations.

### ğŸ“ˆ Scaling the System

The system can be scaled horizontally by:
- â• Adding more worker nodes for Airflow
- ğŸ”„ Implementing database sharding for PostgreSQL
- ğŸš€ Setting up Redis clustering for improved caching performance

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE file for details.

## Happy CodingğŸš€ğŸš€
